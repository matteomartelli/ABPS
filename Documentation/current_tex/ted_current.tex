\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{float}
\usepackage{bytefield}
\usepackage{fullpage}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{bytefield}
\usepackage{enumerate}

%opening
\title{ABPS: TED fragmentation fixing}
\author{Matteo Martelli}

\begin{document}
\lstset{language=C}
\maketitle


\section{Nelle puntate precedenti}
In questo documento si fa riferimento alla modifiche apportate al componente software TED (Transmis-
sion Error Detector) riguardanti la frammentazione. Per maggiori informazioni su TED e sull’architettura
Always Best Packet Switching (ABPS) si rimanda alla documentazione
precedente. %todo ref

Nello specifico TED offre, tramite una struttura cross-layer, un meccanismo in grado di fornire infor-
mazioni alle applicazioni riguardo l’avvenuta (o mancata) consegna al primo access point dei datagram
UDP trasmessi.

Quando l’applicazione invia un datagram UDP, TED lo marca con un identificativo user-space acces-
sibile dall’applicazione. Successivamente ogni frammento datalink spedito dall’interfaccia di rete viene
associato a quell’identificativo e ad una struttura dati contenenti informazioni sullo stato del frammento.
Quest’ultime vengono poi integrate con le informazioni riguardanti l’avvenuta o mancata consegna (ACK,
NACK) del frammento all’access point e il relativo numero di tentativi di consegna.

Nelle versioni precedenti a questa mancava il corretto supporto per la gestione della frammentazione
in IPv6. Vedremo nella prossima sezione quali modifiche sono state apportate al kernel per il corretto
funzionamento con la frammentazione in IPv6. Come nella versione
precedente lo sviluppo è stato continuato per il kernel 4.0.1.

Infine nella sezione \ref{sec:app} vedremo le modifiche apportate all’applicazione per la gestione delle notifiche
di TED dei datagram frammentati oltre a qualche esempio d’utilizzo.


\section{Modifiche Kernel}
Prima di mostrare le modifiche effettuate nel kernel ricordiamo
brevemente come sono formati gli header dei pacchetti IPv6.

\subsection{Header IPv6}
In particolare siamo interessati all'header del pacchetto IP che nella
versione 6 è composta da un parte fissa (fixed) e una parte variabile
formata da header opzionali chiamati extension header. \\

La figura \ref{fig:fixedhdr} mostra il formato del fixed header IPv6. 

\begin{figure} [H]
	\begin{center}
		\begin{bytefield}[bitwidth=1.1em]{32}
			\bitheader{0-31}\\
			
			\bitbox{4}{Version}
			\bitbox{8}{Traffic Class}
			\bitbox{20}{Flow Label}\\
			
			\bitbox{16}{Payload Length}
			\bitbox{8}{Next Header}
			\bitbox{8}{Hop Limit} \\
			
			\wordbox{4}{Source Address} \\
			\wordbox{4}{Destination Address} \\
		\end{bytefield}
		\caption{Formato fixed header IPv6}
		\label{fig:fixedhdr}
	\end{center}
\end{figure}

Notiamo che a differenza dei pacchetti IPv4 non sono presenti i campi
\emph{Flags} e \emph{Fragment Offset} utilizzati nella versione 4 per
ottenere informazioni sulla frammentazione. Per tale scopo, in IPv6, bisogna far
riferimento all'extension header \emph{Fragment}, mostrato in figura
\ref{fig:fragmenthdr}, nel quale sono
contenute le informazioni necessarie per riasseblare i pacchetti
originali.

\begin{figure} [H]
	\begin{center}
		\begin{bytefield}[bitwidth=1.1em]{32}
			\bitheader{0-31}\\
			
			\bitbox{8}{Next Header}
			\bitbox{8}{Reserved}
			\bitbox{13}{Fragment Offset}
			\bitbox{2}{Res}
			\bitbox{1}{M} \\

			\wordbox{1}{Identification} \\
		\end{bytefield}
		\caption{Formato fragment extension header IPv6.
I campi \emph{Res} e
\emph{Reserved} indicano spazio riservato inizializzato a 0. Il campo
\emph{M} si riferisce al campo \emph{More Fragment} }
		\label{fig:fragmenthdr}
	\end{center}
\end{figure}


Gli extension header sono situati tra il fixed header e gli header dei
protocolli di livello superiore. Tramite il campo \emph{Next Header} gli header
formano una catena. In particolare il campo \emph{Next Header} del fixed
header indica il tipo del primo extension header e il \emph{Next Header}
dell'ultimo extension header (o del fixed header ove non ci fosse nessun
extension header) indica il tipo dell'header del protocollo di livello
superiore (ad esempio TCP o UDP).

\subsection{Frammentazione IPv6 in TED}
La modifica principale risiede nella funzione
\texttt{ipv6\_get\_udp\_info} la quale si occupa di recuperare le
informazioni sul frammento IPv6 del relativo frame 802.11
 al momento del suo invio.\\

Nella nuova versione si scorre innanzitutto la catena degli header fino
ad incontrare l'header fragment:
\begin{lstlisting}
/* Variables initialization */
*fragment_offset = *more_fragment = hdrs_len = error = 0;
nexthdr = ipv6_hdr(skb)->nexthdr;
target = NEXTHDR_FRAGMENT;

do {
	struct ipv6_opt_hdr _hdr, *hp;
	unsigned int hdrlen;
	found = (nexthdr == target);

	if ((!ipv6_ext_hdr(nexthdr)) || nexthdr == NEXTHDR_NONE) {
		break;
	}

	hp = skb_header_pointer(skb, offset, sizeof(_hdr), &_hdr);
	if (hp == NULL) {
		error = -EBADMSG;
		break;
	}

	if (nexthdr == NEXTHDR_FRAGMENT) {
		hdrlen = 8;
	} else if (nexthdr == NEXTHDR_AUTH) {
		hdrlen = (hp->hdrlen + 2) << 2;
	} else
		hdrlen = ipv6_optlen(hp);

	if (!found) {
		nexthdr = hp->nexthdr;
		offset += hdrlen;
	}

	hdrs_len += hdrlen;
} while (!found);
\end{lstlisting}

In realtà questa operazione è un
controllo di sanità in quanto secondo le specifiche dell'RFC 2460\cite{rfc2460}
l'header fragment
dovrebbe essere il diretto successore del fixed header. 
Ad ogni modo dopo aver indivuato l'header fragment si può accedere alla
bitmap \texttt{frag\_off} della relativa struttura dati. Tramite la
bitmap si possono ottenere quindi il campo \emph{Fragment Offset} e il
campo \emph{More
Fragment} del frammento:

\begin{lstlisting}
/* fh is the pointer to the fragment header struct and it is retreived
according to the offset from the begging of the packet */
fh = skb_header_pointer(skb, offset, sizeof(_frag), &_frag);

if (fh) {
	*fragment_offset = ntohs(fh->frag_off) & ~0x7;
	*more_fragment = ((fh->frag_off & htons(IP6_MF)) > 0);
} 
\end{lstlisting}
 
Infine l'ultimo campo che ci interessa ottenere è la lunghezza del
frammento. La parte frammentabile è tutto quello che segue l'header
fragment, quindi eventuali altri extension header IPv6, gli header dei
protocolli dei livelli superiori e il frammento dati del messaggio.
Bisogna quindi togliere dalla dimensione del frammento indicata dal
campo \emph{Payload} del fixed header, la dimensione dell'header fragment.
Questo perchè il campo \emph{Payload} esclude già la dimensione del fixed
header e perchè l'header fragment è il diretto successore del fixed
header; inoltre tutto quello che segue va considerato parte del
frammento\footnote{Sempre per controllo di sanità, viene sotratto al
payload
tutto quello che parte dalla fine del fixed header fino alla fine
dell'header fragment.}:

\begin{lstlisting}
*fragment_data_length = ntohs(payload_iphdr->payload_len) - hdrs_len;
\end{lstlisting}

A seguito di queste modiche il kernel con TED abilitato riesce
correttamente ad ottenere le informazioni sulla frammentazione anche per
IPv6.

\section{Modifiche Applicazione}
\label{sec:app}
%TODO cosa fa l'applicazione di test?

Al fine di verificare la corretta gestione delle notifiche TED per i
datagram UDP framment, sono state apportate molteplici modifiche
all'applicazione di test. Le principali verrano spiegate in questa
sezione.
\subsection{Gestione Asincrona delle Notifiche}
Come prima considerazione si è dovuto modificare la gestione della
ricezione delle notifiche. Nella versione precedente era stata scelta
una politica sincrona, ovvero per ogni messaggio spedito si attendeva
la relativa
notifica TED prima di procedere alla spedizione del messaggio
successivo. È evidente che tale approccio aggiunge un rallentamento
notevole all'applicazione. 
Inoltre tale approccio non potrebbe essere applicato se
l'applicazione spedisse datagram UDP di dimensione maggiore del MTU
inquanto per ogni datagram spedito bisognerebbe attendere le notifiche
di tutti i frammenti (ricordiamo che TED invia una notifica per ogni
frame 802.11 spedito, quindi per ogni frammento del datagram UDP
originale).

Si è scelto quindi di passare ad una gestione asincrona delle notifiche.
Esistono diversi articoli\cite{polling1,polling2} che mostrano e
comparano i possibili sistemi per gestire in modo asincrono i socket
descriptor.
Il recente \emph{epoll} introduce varie ottimizazzioni in termini
prestazionali rispetto a \emph{select} e \emph{poll}.
Tuttavia tali ottimizzazioni sembrerebbero avere effetto solo con un
gran numero di socket e al contrario sembrano peggiore le prestazioni con
un numero basso di socket descriptor. 

È da considerare inoltre che l'applicazione di test 
è un primo passo verso l'implementazione di un proxy client descritto da
ABPS\cite{abps} in cui il numero di socket da gestire è piccolo:
generalmente un socket per l'applicazione, e due o tre per il numero di
interfacce.

Ad ogni modo è molto interessate la gestione degli eventi in modalità edge-triggered 
introdotto da epoll. Nella modalità edge-triggered gli eventi vengono
segnalati all'applicazione solo c'è un cambio di stato nei file
descriptor monitorati. Vediamo di seguito un esempio dal man di epoll per
chiarezza.\\

Suppose that this scenario happens:

\begin{enumerate}
	\item The file descriptor that represents the read side of a pipe
(rfd) is registered on the epoll instance.
	\item A pipe writer writes 2 kB of data on the write side of the pipe.
	\item A  call  to  epoll\_wait(2)  is  done  that  will return rfd as a ready file
          descriptor.
	\item The pipe reader reads 1 kB of data from rfd.
	\item A call to epoll\_wait(2) is done.
\end{enumerate}
If the rfd file descriptor has been added to the  epoll  interface  using  the
EPOLLET  (edge-triggered)  flag, the call to epoll\_wait(2) done in step 5 will
probably hang despite the available data still present in the file input  buffer; 
meanwhile the remote peer might be expecting a response based on the data
it already sent.

$\cdots$\\
The suggested way  to  use  epoll  as  an
edge-triggered (EPOLLET) interface is as follows:
\begin{enumerate}[i]
	\item  with nonblocking file descriptors; and
    \item  by  waiting  for  an  event  only  after read(2) or write(2) return
                  EAGAIN.
\end{enumerate}
% epoll, why epoll, epoll vs. select

Nel caso in cui la nostra applicazione inviasse datagram UDP molto
grandi (supponiamo $N*MTU$) verso una socket $sd$, per ogni messaggio 
inviato avremmo $N$ notifiche TED provenienti dal kernel per $sd$. 
Quindi con invii di messaggi molto frequenti da parte
dell'applicazione, si potrebbe avere un gran overhead di segnalazione
eventi da parte del kernel se venisse effettuata per ogni $N$ frammenti
del messaggio originale. Utilizzando l'edge-triggered invece avremmo un
segnale solo al primo messaggio TED introdotto nella coda degli errori
(ERRQUEUE). I successivi messaggi TED verrano introdotti, senza essere
segnalati all'applicazione, nella ERRQUEUE che dovrà però venir svuotata ogni
volta che risulta essere non vuota.

Di seguito vediamo il main loop dell'applicazione di test:
\begin{lstlisting}
/* Main epoll loop. Wait for events on the socket descriptor.
 * If an EPOLLOUT event is triggered a new message can be sent.
 * If an EPOLLERR event is triggered some ted error message 
 * may be present in the errqueue. */
for (;;) {

	nfds = epoll_wait(epollfd, events, MAX_EPOLL_EVENTS, -1);
	if (nfds == -1)
		utils_exit_error("epoll_wait error\n");
	
	for (i = 0; i < nfds; i++) {

		/* Send a new message if the socket is ready for writing */
		if (events[i].events & EPOLLOUT && idx < conf.n_packets) {
			send_new_msg(hashtb);
			idx++;
		}

		/* If there are pending TED error messages 
		 * in the errqueue, receive them and print TED infos. */
		if (events[i].events & EPOLLERR)
			recv_ted_errors(hashtb);

	}
}

\end{lstlisting}

Essenzialmente vengono inviati un numero di pacchetti
\texttt{conf.n\_packets}
(di default o specificati dall'utente) ad un server e si controlla dopo
ogni invio se ci sono messaggi di errore, tramite l'evento EPOLLERR, per
il socket descriptor monitorato (in questo caso ne è solamente uno).
Se ci sono messaggi di errore pendenti viene invocata la funzione 
\texttt{recv\_ted\_errors()} che essenzialemente legge le notifiche TED 
dalla coda ERRQUEUE fino a che non risulta vuota (recv ritorna EAGAIN).
Per ogni notifica ricevuta l'applicazione riempie una struttura
\texttt{ted\_info\_s} che verrà utilizzata per ricomporre i frammenti
e/o fornire informazioni
sullo stato del pacchetto originale:
\begin{lstlisting}
struct ted_info_s {
	uint32_t msg_id;
	uint8_t retry_count;
	uint8_t status;
	uint16_t frag_length;
	uint16_t frag_offset;
	uint8_t more_frag;
	uint8_t ip_vers;
	char *msg_pload;
};
\end{lstlisting}

\subsection{Gestione della Frammentazione}
Vediamo adesso come vengono gestite le notifiche TED dei messaggi
frammentati. Ricordiamo che per ogni messaggio UDP abbastanza grande da
venir frammentato, vengono ricevute un numero di notifiche TED pari al
numero di frammenti del messaggio originale. Lo scopo dell'applicazione
di test è quello di riassemblare le notifiche frammentate in modo da
fornire delle informazioni medie sul corrispondente messaggio
precedentemente inviato.

A tal proposito viene utilizzata un hashtable di strutture riguardanti i
messaggi inviati:
\begin{lstlisting}
struct msg_info_s {
	int size;
	uint32_t id;
	struct ted_info_s *frags[MAX_FRAGS];
	int n_frags;
	short int last_frag_received;
};
\end{lstlisting}

Quindi di ogni messaggio inviato viene salvata la dimensione
\texttt{size} e l'identificatore \texttt{id} assegnato dal
kernel. Inoltre vengono predisposte le variabili utilizzate in seguito
per ricomporre i frammenti: \texttt{frags} è un array di struct
\texttt{ted\_info\_s} le quali andranno a contenere le informazioni di
ogni singola notifica TED; \texttt{n\_frags} è il numero di frammenti
attualmente ricevuti (inizializzato a 0) e \texttt{last\_frag\_received}
è un booleano che indica se è stato ricevuto o meno l'ultimo frammento
(per posizione)\footnote{Non necessariamente l'ultimo frammento per
posizione viene ricevuto cronologicamente dopo i suoi predecessori}.\\

Oltre a memorizzare nell'hashtable ogni messaggio spedito, 
per ogni notifica TED ricevuta viene controllato se quest'ultima \underline{non} è
 una
notifica di un frammento (oppure lo è), ovvero se i valori \emph{morefrag}
e \emph{frag\_offset} risultano entrambi zero (o altrimenti).
Nel caso in cui fosse un frammento viene cercata nell'hashtable il
messaggio originale corrispondente in base all'identificatore
\texttt{msg\_id} presente nella struct \texttt{ted\_info\_s} della
notifica. Ricordiamo infatti che TED assegna ad ogni notifica
di un frammento l'id del messaggio originale.\\

Una volta riottenuta dall'hashtable la struttura \texttt{msg\_info\_s} del
meessaggio
originale vi si aggiunge la struct \texttt{ted\_info\_s} della notifica
all'array \texttt{frags}.

Questa operazione viene effettuata per ogni notifica TED di un frammento
ricevuta, finchè non vengono ricevuti tutti i messaggi.
Se viene ricevuta la notifica del frammento che ha
valore \texttt{more\_frag} uguale a 0, ovvero l'ultimo frammento di
posizione, oppure se viene ricevuta una notifica di qualsiasi frammento
ma è già stato ricevuto l'ultimo di posizione,
si procede ad ordinare, secondo gli offset, tutti i frammenti già ricevuti. 
Se la somma delle dimensioni di ciascun frammento è uguale alla
dimensione del messaggio originale (più l'header UDP)  allora si considerano
 validi i frammenti e si calcolano la media del numero di \emph{ack} e di
\emph{retry count} del messaggio originale.
Quest'ultima operazione viene eseguita dalla funzione
\texttt{try\_recompose} riportata qui di seguito:

\begin{lstlisting}
int try_recompose(struct msg_info_s *msg_origin)
{
	...
	/* Sort fragments by the fragment offsets */
	qsort(msg_origin->frags, msg_origin->n_frags,
	      sizeof(struct ted_info_s *), compare_frags);
	
	tot_len = 0;
	acked_avg = retry_count_avg = 0.0;
	if (msg_origin->frags[msg_origin->n_frags - 1]->more_frag == 0) {
		for (i = 0; i < msg_origin->n_frags; i++) { 
			tot_len += msg_origin->frags[i]->frag_length;
			acked_avg += (float)msg_origin->frags[i]->status;	
			retry_count_avg += (float)msg_origin->frags[i]->retry_count;
		}
		acked_avg /= (float)msg_origin->n_frags;
		retry_count_avg /= (float)msg_origin->n_frags;
	}
	if (tot_len != msg_origin->size + UDP_HEADER_SIZE) {
		printf("recomposition failed.\n");
		return 0;
	}
	return 1; /* Success */

}
\end{lstlisting}


Non c'è ancora una gestione dell'errore: potrebbe accadere che arrivino
le notifiche di tutti
i frammenti ma la somma delle loro dimensioni non corrisponda al
messaggio originale. Inoltre potrebbe accadere che non tutte le
notifiche arrivino. Un'idea di sviluppo potrebbe essere quella di
controllare periodicamente l'hashtable e rimuovere quei messaggi che non
hanno ricevuto tutte le notifiche entro un certo tempo limite. 
Tali considerazioni potrebbero essere rianalizzate per le future versioni. 

\subsection{Refactoring e Organizzazione}
Rispetto alla versione precedente è stata effettuata una consistente
riorganizzazione e un refactoring del codice sorgente.
Innanzitutto sono state unificate le due applicazioni per IPv4 e IPv6 in
un'unica applicazione potendo scegliere all'invocazione quale versione
utilizzare. \\

Inoltre la gestione dei log in formato json presente nella versione
precedente è stata rimossa in quanto non più applicabile con la gestione
asincrona delle notifiche TED.\\

Infine è stata riorganizzata la struttura file portando tutte le
constanti e le strutture in file header apposititi, \texttt{consts.h} e
\texttt{structs.h}, aggiungendo i sorgenti per funzioni di utilità generiche,
\texttt{utils.c/h}, e separando le funzioni di rete dalle funzioni di
gestione delle notifiche TED relativamente in \texttt{network.c/h} e
\texttt{tederror.c/h}.
%struttura file

\subsection{Utilizzo}
%usage, esempio invocazione e output


\bibliography{biblio}{}
\bibliographystyle{plain}
\end{document}
